![App Screenshot](assets/LithiumBattery_App.png)
---

# ğŸ”‹ Patent Innovation Predictor

A cutting-edge AI-powered system that intelligently analyzes, explores, and forecasts innovation patterns in **patent datasets** across **diverse technology domains**. This project blends the strengths of **LLMs**, **vector databases**, **semantic search**, **SerpAPI**, and **multi-agent reasoning** into a unified tool that aids R\&D leaders, analysts, and strategists.

It provides both **CLI and GUI** interfaces to explore patent data, refine search results, generate insights, and forecast future trends.

---

## ğŸš€ Key Capabilities

* ğŸ” **Keyword, Semantic & Hybrid Patent Search** using OpenSearch
* ğŸ¤– **Multi-Agent Analysis** (CrewAI) for scoped, role-based patent forecasting
* ğŸ” **Iterative Refinement** of search queries based on results
* ğŸ“ˆ **Trend Forecasting** to identify innovation hotspots and research gaps
* ğŸŒ **Streamlit Interface** for intuitive exploration and export
* ğŸ”Œ **SerpAPI Integration** for live patent updates and augmenting search results
* ğŸ“ **Structured Outputs** in logs and reports folders for reproducibility
* ğŸ’» **Dual Modes**: Command Line and GUI-based for maximum usability

---

## ğŸ§° Technology Stack

| Component      | Role & Importance                                                                      |
| -------------- | -------------------------------------------------------------------------------------- |
| **Python**     | Core programming language                                                              |
| **Ollama**     | Local LLM runtime for efficient, offline model execution                               |
| **LangChain**  | Chains prompts and manages context through modular pipelines                           |
| **CrewAI**     | Defines collaborative agents and task workflows                                        |
| **OpenSearch** | Search engine for hybrid (vector + keyword) querying over patent documents             |
| **Docker**     | Deploys OpenSearch reliably in isolated environments                                   |
| **Streamlit**  | Builds the interactive graphical dashboard                                             |
| **SerpAPI**    | Enables real-time enrichment from the web (e.g., fresh patent listings, market trends) |
| **.env**       | Secures sensitive environment variables like API keys                                  |

---

## ğŸ“ Folder Structure

```
Patent_Predictor/
â”œâ”€â”€ embeddings/                     # Embedding model configuration & logic
â”‚   â””â”€â”€ get_embedding.py
â”œâ”€â”€ opensearch_client/              # OpenSearch connection wrapper
â”‚   â””â”€â”€ get_opensearch_client.py
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ logs/                       # LLM logs and agent diagnostics
â”‚   â””â”€â”€ patent_analysis/           # Generated reports and summaries
â”œâ”€â”€ patent_search_tools.py         # Search logic: semantic, keyword, hybrid, iterative
â”œâ”€â”€ patent_crew.py                 # Agent setup and forecasting pipeline using CrewAI
â”œâ”€â”€ agentic_rag.py                 # CLI interface controller
â”œâ”€â”€ app.py                         # Streamlit GUI application
â”œâ”€â”€ requirements.txt               # Python dependencies
â””â”€â”€ README.md                      # This file
```

---

## âš™ï¸ Setup Instructions

### âœ… Prerequisites

* Python 3.9+
* Docker (for OpenSearch)
* Ollama (to run LLMs locally)
* SerpAPI Key for live web enrichment

### ğŸ§ª Installation

```bash
# Clone repository
$ git clone https://github.com/yourusername/Patent_Predictor.git
$ cd Patent_Predictor

# Setup Python environment
$ python -m venv venv
$ source venv/bin/activate  # or venv\Scripts\activate (Windows)

# Install Python packages
$ pip install -r requirements.txt
```

### ğŸ§  Ollama Setup (Local LLM)

```bash
# Start the Ollama server
$ ollama serve

# Pull a desired model (e.g. llama2, mistral)
$ ollama pull llama2:latest
```
---

## ğŸ§ª CLI Interface

Run the CLI-based interactive menu:

```bash
$ python agentic_rag.py
```

---

### Available Options:

1. Run full patent forecasting pipeline
2. Search patents (Keyword, Semantic, Hybrid)
3. Perform multi-step refinement search
4. View Ollama system status
5. List locally available models
6. Exit

---

## ğŸŒ Streamlit UI

Launch the graphical interface:

```bash
$ streamlit run app.py
```

### Features:

* Choose **search type** (keyword, semantic, hybrid)
* Select **LLM model** from dynamic Ollama model list
* Input patent queries with result ranking
* Visual summary, PDF export, logs display
* Dynamic status panel with live feedback

---

## ğŸ¤– Agentic Pipeline (CrewAI)

| Agent Role                | Responsibility                                               |
| ------------------------- | ------------------------------------------------------------ |
| **Research Director**     | Defines problem scope, time range, and tech objectives       |
| **Patent Retriever**      | Queries OpenSearch and external sources for relevant patents |
| **Patent Analyst**        | Detects trends, leading companies, innovation categories     |
| **Innovation Forecaster** | Predicts next-gen technologies, recommends R\&D directions   |

Each role is powered by a separate LLM instance and chained using `CrewAI` to simulate human-like task delegation and reasoning.

---

## ğŸ”¬ Core Functionalities

* ğŸ” Unified **Hybrid Search**: combines keyword and vector queries
* â›“ï¸ **Multi-step Reasoning**: through sequential agent pipelines
* ğŸ“ˆ **Forecast Module**: predicts R\&D areas to watch or invest in
* ğŸ“¡ **SerpAPI Integration**: optional fresh data fetching for better accuracy
* ğŸ§  **Offline LLM Inference**: runs via Ollama without cloud latency or API limits
* ğŸ’¾ **Full traceability**: logs and agent traces are exportable for auditing

---

## ğŸ“¬ Contact & Author

**Anish Tripathi**
ğŸ”¹ AI/ML Developer | LLM Engineering | Semantic Search | Vector DBs | RAG Workflows
ğŸ”— [GitHub](https://github.com/anish3565)
ğŸ“§ [tripathianish12@gmail.com](mailto:tripathianish12@gmail.com)

---
